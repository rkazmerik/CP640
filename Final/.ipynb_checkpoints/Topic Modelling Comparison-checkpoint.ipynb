{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling: A Comparison of Evaluation Methods\n",
    "\n",
    "- Wilfrid Laurier University (Winter 2018)\n",
    "- CS640 - Introduction to Machine Learning\n",
    "- Ryan Kazmerik (175826410)\n",
    "\n",
    "## Overview\n",
    "This notebook includes an experiment to compare intrinsic vs. extrinsic evaluation methods when considering topic modelling and contains the following sections:\n",
    "\n",
    "1. [Dataset](#dataset)\n",
    "2. [Vectorizing Features](#features)\n",
    "3. [Fitting Models](#models)\n",
    "4. [Viewing Topic Terms](#topterms)\n",
    "5. [Extrinsic Evaluation](#extrinsic)\n",
    "6. [Intrinsic Evaluation](#intrinsic)\n",
    "7. [Comparing Evaluations](#evaluations)\n",
    "8. [Visualizing Results](#visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='dataset'>Dataset\n",
    "### 1. 20newsgroups\n",
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics and has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "Let's import the 20newsgroups dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-NEWSGROUPS DATASET:\n",
      "  Documents= 2609\n",
      "  Categories= 3\n",
      "\n",
      "SAMPLE DOCUMENT: \n",
      "\n",
      "Actually, Hiten wasn't originally intended to go into lunar orbit at all,\n",
      "so it indeed didn't have much fuel on hand.  The lunar-orbit mission was\n",
      "an afterthought, after Hagoromo (a tiny subsatellite deployed by Hiten\n",
      "during a lunar flyby) had a transmitter failure and its proper insertion\n",
      "into lunar orbit couldn't be positively confirmed.\n",
      "\n",
      "It should be noted that the technique does have disadvantages.  It takes\n",
      "a long time, and you end up with a relatively inconvenient lunar orbit.\n",
      "If you want something useful like a low circular polar orbit, you do have\n",
      "to plan to expend a certain amount of fuel, although it is reduced from\n",
      "what you'd need for the brute-force approach.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    'rec.sport.baseball',\n",
    "    'sci.space',\n",
    "    'talk.religion.misc'\n",
    "]\n",
    "\n",
    "# ds1 = 20-newsgroups dataset\n",
    "ds1 = fetch_20newsgroups(subset='all', categories=categories, shuffle=True,  \n",
    "                         random_state=1, remove=('headers','footers','quotes'))\n",
    "\n",
    "print ('20-NEWSGROUPS DATASET:')\n",
    "print ('  Documents=', len(ds1.data))\n",
    "print ('  Categories=', len(ds1.target_names))\n",
    "print ()\n",
    "print ('SAMPLE DOCUMENT: ')\n",
    "print (ds1.data[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='features'>Vectorizing Features\n",
    "The text in the documents must be parsed to remove stop words (tokenization) and the words need to be encoded as floating point values to be used as input for our clustering algorithm (vectorization).\n",
    "\n",
    "Let's create some feature vectors for our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-newsgroups features:\n",
      "   Num features: 1000\n",
      "   Non-zero components: 25.6561901112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "my_additional_stop_words = ['like','don']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)\n",
    "\n",
    "# Create some vectorizers for each algorithm\n",
    "km_vectorizer = TfidfVectorizer(max_df=0.2, min_df=2, \n",
    "                     max_features=1000, stop_words='english')\n",
    "\n",
    "lda_vectorizer = CountVectorizer(max_df=0.95, min_df=2, analyzer='word',\n",
    "                     max_features=1000, stop_words=stop_words, token_pattern = r'\\b[a-zA-Z]{3,}\\b')\n",
    "\n",
    "plsa_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, \n",
    "                     max_features=1000, stop_words='english')\n",
    "\n",
    "# Generate feature sets for all 3 algorithms\n",
    "fs1 = km_vectorizer.fit_transform(ds1.data)\n",
    "fs2 = lda_vectorizer.fit_transform(ds1.data)\n",
    "fs3 = plsa_vectorizer.fit_transform(ds1.data)\n",
    "\n",
    "print ('20-newsgroups features:')\n",
    "print ('   Num features:', fs1.shape[1])\n",
    "print ('   Non-zero components:', fs1.nnz / float(fs1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='models'>Fitting Models (Kmeans, LDA, PLSA)\n",
    "Three algorithms are used to cluster the results including a standard implementation of Kmeans, Non-negative Matrix Factorization is applied with the generalized Kullback-Leibler divergence which is equivalent to Probabilistic Latent Semantic Analysis (PLSA).\n",
    "\n",
    "Let's cluster our feature sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the kMeans model...\n",
      "   done in: 1.12156295776\n",
      "\n",
      "Fitting the LDA model...\n",
      "   done in: 8.07883620262\n",
      "\n",
      "Fitting the PLSA model...\n",
      "   done in: 0.866367101669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from time import time\n",
    "\n",
    "n_components = 3\n",
    "\n",
    "# Fit the kMeans model KM1=20-newsgroups\n",
    "t0 = time()\n",
    "KM = KMeans(n_clusters=n_components, init='k-means++', max_iter=100, \n",
    "            n_init=1, verbose=0)\n",
    "print ('Fitting the kMeans model...')\n",
    "\n",
    "KM1 = KM.fit(fs1)\n",
    "\n",
    "print ('   done in:', (time()-t0))\n",
    "print ()\n",
    "\n",
    "# Fit the LDA model LDA1=20-newsgroups\n",
    "t0 = time()\n",
    "LDA = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "            learning_method='online', learning_offset=50., random_state=0)\n",
    "print ('Fitting the LDA model...')     \n",
    "LDA1 = LDA.fit(fs2)\n",
    "\n",
    "print ('   done in:', (time()-t0))\n",
    "print ()\n",
    "\n",
    "# Fit the PLSA model PLSA1=20-newsgroups\n",
    "t0 = time()\n",
    "PLSA = NMF(n_components=n_components, random_state=1, beta_loss='kullback-leibler', \n",
    "           solver='mu', max_iter=1000, alpha=.1, l1_ratio=.5)\n",
    "print ('Fitting the PLSA model...')\n",
    "\n",
    "PLSA1 = PLSA.fit(fs3)\n",
    "\n",
    "print ('   done in:', (time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='topterms'>Viewing Topic Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans - Topic model:\n",
      " Topic 0: year game team games baseball hit good players runs braves\n",
      " Topic 1: space nasa shuttle launch orbit moon earth program hst mission\n",
      " Topic 2: god know people does time say did jesus want good\n",
      "\n",
      "LDA - Topic model:\n",
      " Topic 0: year game team good think games baseball hit won just\n",
      " Topic 1: god people jesus just know say think does bible did\n",
      " Topic 2: space nasa earth launch data time shuttle orbit moon spacecraft\n",
      "\n",
      "pLSA - Topic model:\n",
      " Topic 0: think time like just don year years good know way\n",
      " Topic 1: space use like nasa earth orbit thanks new shuttle used\n",
      " Topic 2: people god say think don just way did know read\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_terms = 10\n",
    "terms1 = km_vectorizer.get_feature_names()\n",
    "terms2 = lda_vectorizer.get_feature_names()\n",
    "terms3 = plsa_vectorizer.get_feature_names()\n",
    "\n",
    "print(\"Kmeans - Topic model:\")\n",
    "\n",
    "order_centroids = KM1.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(3):\n",
    "    print(\" Topic %d:\" % i, end='')\n",
    "    for ind in order_centroids[i, :n_terms]:\n",
    "        print(' %s' % terms1[ind], end='')\n",
    "    print ()\n",
    "print()\n",
    "   \n",
    "    \n",
    "print(\"LDA - Topic model:\")\n",
    "\n",
    "for topic_idx, topic in enumerate(LDA1.components_):\n",
    "    message = \" Topic %d: \" % topic_idx\n",
    "    message += \" \".join([terms2[i]\n",
    "                    for i in topic.argsort()[:-n_terms - 1:-1]])\n",
    "    print(message)\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"pLSA - Topic model:\")\n",
    "\n",
    "for topic_idx, topic in enumerate(PLSA1.components_):\n",
    "    message = \" Topic %d: \" % topic_idx\n",
    "    message += \" \".join([terms3[i]\n",
    "                    for i in topic.argsort()[:-n_terms - 1:-1]])\n",
    "    print(message)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='extrinsic'>Extrinsic Evaluation\n",
    "Due to the lack of precise accuracy measurments, often topic modelling is evaluated using an extrinsic measure. That is, a baseline set of results are provided by a human test participant or subject matter expert. For our baseline result set, we will be using a list of 10 human-generated terms for each topic - for more information on the design of this task please see the research paper related to this experiment.\n",
    "\n",
    "### Part 1 : Co-occurance Measure\n",
    "The first part of the extrinsic evaluation will measure the rate of co-occurance between our baseline topics and the modeled topics. Each model will be assigned a normalized score between 0 - 1, a threshold of >0.5 has been assigned to qualify as a performant topic model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic | Method | t1 | t2 | t3 | t4 | t5 | t6 | t7 | t8 | t9 | t10 | **CO** | **CS (CO/nt)**\n",
    "------|-------|----|----|----|----|----|----|----|----|----|----\n",
    "0 | **K-means**|space|nasa|shuttle|launch|orbit|moon|earth|mission|hst|program|**8**|**0.8**\n",
    "0 | **LDA**|space|nasa|earth|launch|data|shuttle|orbit|spacecraft|solar|moon|**8**|**0.8**\n",
    "0 |**pLSA**|space|nasa|orbit|new|shuttle|earth|use|program|launch|used|**6**|**0.6**\n",
    "0 |**Baseline**|space|mission|solar|exploration|moon|launch|nasa|orbit|earth|shuttle|**-**|**-**\n",
    "| | | | | | | | | | | | |\n",
    "1 | **K-means**|god|jesus|people|christian|bible|know|koresh|right|christians|say|**3**|**0.3**\n",
    "1 | **LDA**|people|don|god|just|think|know|christian|say|does|jesus|**3**|**0.3**\n",
    "1 |**pLSA**|people|god|say|think|don|just|way|did|know|read|**1**|**0.1**\n",
    "1 |**Baseline**|religion|christian|jesus|muslim|jew|god|faith|view|heaven|scripture|**-**|**-**\n",
    "| | | | | | | | | | | | |\n",
    "2 | **K-means**|year|game|team|games|baseball|hit|good|players|runs|braves|**4**|**0.4**\n",
    "2 | **LDA**|year|game|team|games|baseball|hit|won|runs|players|league|**5**|**0.5**\n",
    "2 |**pLSA**|think|time|like|just|don|year|years|game|know|way|**1**|**0.1**\n",
    "2 |**Baseline**|religion|christian|jesus|muslim|jew|god|faith|view|heaven|scripture|**-**|**-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurance measures (threshold > .5)\n",
      " K-means= 0.5 fail\n",
      " LDA= 0.533333333333 pass\n",
      " pLSA= 0.266666666667 fail\n"
     ]
    }
   ],
   "source": [
    "#Calculate overall co-occurance score for each method\n",
    "n_topics = 3\n",
    "\n",
    "km_co_score = (0.8+0.3+0.4) / n_topics\n",
    "lda_co_score = (0.8+0.3+0.5) / n_topics\n",
    "plsa_co_score = (0.6+0.1+0.1) / n_topics\n",
    "\n",
    "print ('Co-occurance measures (threshold > .5)')\n",
    "print (' K-means=', km_co_score, 'fail')\n",
    "print (' LDA=', lda_co_score, 'pass')\n",
    "print (' pLSA=', plsa_co_score, 'fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Probability Measure\n",
    "For the second part of our extrinsic evaluation, we will select the algorithms above our co-currance threshold from part 1 (LDA) and calculate the probabilities of each term in the topic model against our baseline terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic | Term | Probability | Co-occurance | PS\n",
    "------|------|-------------|--------------|------\n",
    "0|space|1262.39|1|1262.39\n",
    "0|nasa|488.90|1|488.90\n",
    "0|earth|418.79|1|418.79\n",
    "0|launch|348.33|1|348.33\n",
    "0|data|282.03|0|0\n",
    "0|shuttle|286.92|1|286.92\n",
    "0|orbit|284.63|1|284.63\n",
    "0|spacecraft|260.17|0|0\n",
    "0|solar|258.66|1|258.66\n",
    "0|moon|262.45|1|262.45\n",
    "1|people|709.44|0|0\n",
    "1|don|693.71|0|0\n",
    "1|god|664.35|1|664.35\n",
    "1|just|648.34|0|0\n",
    "1|think|623.70|0|0\n",
    "1|know|570.54|0|0\n",
    "1|christian|209.42|1|209.42\n",
    "1|say|449.83|0|0\n",
    "1|does|434.53|0|0\n",
    "1|jesus|416.45|1|416.45\n",
    "2|year|487.19|0|0\n",
    "2|game|428.48|1|428.48\n",
    "2|team|319.71|1|319.71\n",
    "2|games|276.94|0|0\n",
    "2|baseball|260.40|1|260.40\n",
    "2|hit|240.49|0|0\n",
    "2|won|207.12|0|0\n",
    "2|runs|202.95|0|0\n",
    "2|players|186.44|1|186.44\n",
    "2|league|182.51|1|182.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability scores:\n",
      " Topic 0= 3611.07\n",
      " Topic 1= 1290.22\n",
      " Topic 2= 1377.54\n",
      "Probability measure= 627.883\n"
     ]
    }
   ],
   "source": [
    "#Calculate probability measure for all topics\n",
    "n_terms = 10\n",
    "\n",
    "topic0_ps = (1262.39+488.90+418.79+348.33+286.92+284.63+258.66+262.45)\n",
    "topic1_ps = (664.35+209.42+416.45)\n",
    "topic2_ps = (428.48+319.71+260.40+186.44+182.51)\n",
    "\n",
    "print ('Probability scores:')\n",
    "print (' Topic 0=', topic0_ps)\n",
    "print (' Topic 1=', topic1_ps)\n",
    "print (' Topic 2=', topic2_ps)\n",
    "print ('Probability measure=', (topic0_ps/n_terms)+(topic1_ps/n_terms)+(topic2_ps/n_terms))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='intrinsic'>Intrinsic Evaluation\n",
    "The most widely used instrinsic evaluation method is known as **Perplexity** which can be thought of as the inverse per-word likelihood of our LDA model. The accurate way to calculate perplexity is using a hold-out test set to compare against our trained model. \n",
    "\n",
    "Let's evaluate our LDA model using perplexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the LDA model...\n",
      "   done in: 5.02224087715\n",
      "\n",
      "Perplexity=  1435.8732953881436\n"
     ]
    }
   ],
   "source": [
    "# Create test and training data sets\n",
    "ds_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,  \n",
    "                         random_state=1, remove=('headers','footers','quotes'))\n",
    "\n",
    "ds_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True,  \n",
    "                         random_state=1, remove=('headers','footers','quotes'))\n",
    "\n",
    "# Vectorize the datasets\n",
    "fs_train = lda_vectorizer.fit_transform(ds_train.data)\n",
    "fs_test = lda_vectorizer.fit_transform(ds_test.data)\n",
    "\n",
    "# Fit the LDA model to the training features\n",
    "t0 = time()\n",
    "print ('Fitting the LDA model...')     \n",
    "\n",
    "LDA_train = LDA.fit(fs_train)\n",
    "print ('   done in:', (time()-t0))\n",
    "print ()\n",
    "\n",
    "# Calculate model perplexity using the test set\n",
    "perplexity = LDA_train.perplexity(fs_test)\n",
    "print ('Perplexity= ',perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='evaluations'>Comparing Evaluation Methods\n",
    "Now that we have generated both extrinsic and intrinsic evaluation methods, let's compare the measurements as we increase the number of features to see how they correspond to each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the LDA model w/ 50 features...\n",
      "   done in: 4.65968894958\n",
      "Probability measure= 7.586414930619255\n",
      "Perplexity=  59.158545405828065\n",
      "\n",
      "Fitting the LDA model w/ 100 features...\n",
      "   done in: 5.41513180733\n",
      "Probability measure= 6.771777302664992\n",
      "Perplexity=  116.7780878600271\n",
      "\n",
      "Fitting the LDA model w/ 250 features...\n",
      "   done in: 7.3759059906\n",
      "Probability measure= 133.576141356697\n",
      "Perplexity=  306.68124274805086\n",
      "\n",
      "Fitting the LDA model w/ 500 features...\n",
      "   done in: 6.3376789093\n",
      "Probability measure= 269.4394083745913\n",
      "Perplexity=  671.0099714832123\n",
      "\n",
      "Fitting the LDA model w/ 750 features...\n",
      "   done in: 7.12062811852\n",
      "Probability measure= 279.70652470326814\n",
      "Perplexity=  1036.9797138818356\n",
      "\n",
      "Fitting the LDA model w/ 1000 features...\n",
      "   done in: 6.45490098\n",
      "Probability measure= 279.99911393702206\n",
      "Perplexity=  1468.4296523668365\n",
      "\n",
      "Fitting the LDA model w/ 1250 features...\n",
      "   done in: 7.41556310654\n",
      "Probability measure= 140.01920023577514\n",
      "Perplexity=  1881.6217119420119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_array = [50,100,250,500,750,1000,1250]\n",
    "x_data = []\n",
    "y1_data = []\n",
    "y2_data = []\n",
    "\n",
    "for n_features in f_array:\n",
    "    \n",
    "    # Create the vectorizer and generate features\n",
    "    e_vectorizer = CountVectorizer(max_df=0.95, min_df=2, analyzer='word',\n",
    "                         max_features=n_features, stop_words='english')\n",
    "\n",
    "    e_fs = e_vectorizer.fit_transform(ds1.data)\n",
    "\n",
    "    # Fit the LDA model for evaluation\n",
    "    t0 = time()\n",
    "\n",
    "    print ('Fitting the LDA model w/',n_features,'features...')     \n",
    "    e_LDA = LDA.fit(e_fs)\n",
    "\n",
    "    print ('   done in:', (time()-t0))\n",
    "\n",
    "    # Get the vectorizer terms and the base class terms\n",
    "    v_terms = e_vectorizer.get_feature_names()\n",
    "    bl_terms_0 = ['space','mission','solar','exploration','moon','launch','nasa','orbit','earth','shuttle']\n",
    "    bl_terms_1 = ['religion','christian','jesus','muslim','jew','god','faith','view','heaven','scripture']\n",
    "    bl_terms_2 = ['year','game','team','games','baseball','hit','won','runs','players','league']\n",
    "\n",
    "    # Calculate the total probability\n",
    "    total_prob = 0;\n",
    "    n_bl_terms = len(bl_terms_0) + len(bl_terms_1) + len(bl_terms_2)\n",
    "\n",
    "    for i, term in enumerate (v_terms):\n",
    "        if (term in bl_terms_0): total_prob += e_LDA.components_[0][i]\n",
    "        if (term in bl_terms_1): total_prob += e_LDA.components_[1][i]\n",
    "        if (term in bl_terms_2): total_prob += e_LDA.components_[2][i]\n",
    "\n",
    "    prob_measure = total_prob / n_bl_terms\n",
    "    print ('Probability measure=', prob_measure)\n",
    "\n",
    "    # Calculate the perplexity score\n",
    "    e_train = e_vectorizer.fit_transform(ds_train.data)\n",
    "    e_test = e_vectorizer.fit_transform(ds_test.data)\n",
    "\n",
    "    e_LDA_train = LDA.fit(e_train)\n",
    "\n",
    "    perplexity = e_LDA_train.perplexity(e_test) \n",
    "    print ('Perplexity= ', perplexity)\n",
    "    print ()\n",
    "    \n",
    "    x_data.append(n_features)\n",
    "    y1_data.append(perplexity%3)\n",
    "    y2_data.append(prob_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='visualizations'>Visualizing the Results\n",
    "We can see that as the number of features increases, the probability measure seems to increase, and the perplexity decreases, let's plot these on a line chart to further understand the relationship and identify the elbow point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rkazmerik/318.embed\" height=\"500px\" width=\"1200px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Create traces\n",
    "perp = go.Scatter(x=x_data, y=y1_data, mode='lines+markers', name='Perplexity')\n",
    "prob = go.Scatter(x=x_data, y=y2_data, mode='lines+markers', name='Probability', yaxis='y2')\n",
    "data = [perp, prob]\n",
    "\n",
    "layout = go.Layout(title = 'Perplexity/Probability vs. No. Features',\n",
    "    yaxis = dict(title='Perplexity'),\n",
    "    yaxis2 = dict(title='Probability', overlaying='y', side='right'),\n",
    "    xaxis = dict(title='No. Features'),\n",
    "    autosize=False, width=1200, height=500\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the results above, the perplexity measure would indicate our model is ideal at 100 features, while the probability measure indicates it is ideal at 1000 features.\n",
    "\n",
    "Let's see what our topic model looks like at 100 and 1000 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2645446321562401988629944\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2645446321562401988629944_data = {\"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 2], \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.03364340570739762, 0.8891471508383657, 0.07209301223013775, 0.003470873053434578, 0.010412619160303734, 0.9891988202288547, 0.8615733487176392, 0.05135205389707783, 0.0884396483783007, 0.17271274999559497, 0.13817019999647598, 0.6859163499825057, 0.35023118551834115, 0.18356944896133742, 0.46616978486234373, 0.9985792915279408, 0.3598154009498734, 0.48144314211602784, 0.15710249900628276, 0.22914395443952798, 0.05601296664077351, 0.7179843905771877, 0.9952135733693607, 0.9945384742371386, 0.004851407191400676, 0.7254616092629945, 0.10037833587286717, 0.1733807619622251, 0.003339694590939543, 0.9852099043271653, 0.01001908377281863, 0.7348303490596036, 0.09237867245320731, 0.17425976849127744, 0.7524807743340131, 0.1911707913172898, 0.05694449103068207, 0.8444178087501254, 0.08444178087501254, 0.07069544445349887, 0.7278643851156679, 0.11704351921457976, 0.15361961896913592, 0.16774777930037293, 0.6809761040646092, 0.15177180031938503, 0.13793313365858256, 0.08995639151646688, 0.7736249670416152, 0.7883891352018336, 0.09635867208022411, 0.11387843064026486, 0.4765714633691587, 0.07609124205053794, 0.44853784787685524, 0.04631212259321677, 0.14819879229829366, 0.8058309331219718, 0.02928663322019111, 0.004183804745741588, 0.9664588962663067, 0.003305842487094484, 0.003305842487094484, 0.9917527461283452, 0.9965332500727678, 0.0015331280770350276, 0.0015331280770350276, 0.6427520568414052, 0.23455880747292987, 0.12337184029420338, 0.5187623752941414, 0.14576794016529593, 0.33440880390862004, 0.1553998543756186, 0.5244745085177127, 0.3185697014700181, 0.0035760197952658815, 0.37548207850291754, 0.6222274443762634, 0.03552047493888892, 0.6482486676347228, 0.31524421508263917, 0.9959347989502538, 0.9990338408828829, 0.7738542030770775, 0.1922390979162993, 0.033060227030191604, 0.817863445089436, 0.12282930860317537, 0.05841881750638828, 0.0028864003469400617, 0.9929217193473812, 0.0028864003469400617, 0.014755601178949328, 0.9837067452632886, 0.8414523787736637, 0.14366260125404015, 0.013682152500384777, 0.40048823934962197, 0.18043975619048902, 0.4180921180023526, 0.3022790867155637, 0.5120237591304446, 0.18506882860136553, 0.9911630519102688, 0.010062569054926586, 0.41561668676655866, 0.27707779117770576, 0.3096751783750829, 0.010176450763072309, 0.5800576934951215, 0.41214625590442844, 0.6528115409419072, 0.22578444273178747, 0.12270893626727579, 0.8612879655849849, 0.08011981075209161, 0.06008985806406871, 0.8255109793318568, 0.10620609090819211, 0.07241324380104007, 0.027850764058673847, 0.9668193808939635, 0.007957361159621099, 0.0036360486098809815, 0.5454072914821473, 0.4508700276252417, 0.006220185907805279, 0.993156349946243, 0.00207339530260176, 0.4546667987734026, 0.4041482655763579, 0.14237041173712608, 0.15252806787675133, 0.32177154045232476, 0.5244458224255423, 0.014202716637211364, 0.9799874479675841, 0.007101358318605682, 0.2663142014129826, 0.1401653691647277, 0.5933667294640139, 0.8788866564710037, 0.10355873781673842, 0.01635137965527449, 0.00853624758058412, 0.03841311411262854, 0.9560597290254212, 0.7432673765353711, 0.11867294247203404, 0.13741077549393416, 0.15194273452438545, 0.6435221697503384, 0.2055695820035803, 0.42388040982943215, 0.19444055496762944, 0.38110348773655367, 0.01298008831922895, 0.9475464473037134, 0.03894026495768685, 0.8454895453317991, 0.13815188649212404, 0.016578226379054883, 0.9281061813215145, 0.061328602289967914, 0.008177146971995721, 0.49509943673602946, 0.4107074872923881, 0.09564420936946023, 0.6974939469452778, 0.13413345133563034, 0.16692162832878443, 0.7195132432638175, 0.12037483917721661, 0.16141171616944955, 0.0785546899067664, 0.0785546899067664, 0.8456181325257794, 0.004450308408678841, 0.19581356998186902, 0.8010555135621914, 0.8992697793293183, 0.09332044879832549, 0.00565578477565609, 0.9698703397151645, 0.027192626347154143, 0.8171235961741293, 0.02269787767150359, 0.1609485871252073, 0.053791073088965365, 0.923413421360572, 0.022412947120402232, 0.2770723545813973, 0.3333526766057436, 0.38963299863008993, 0.021154662816936065, 0.9766402667152151, 0.003909489788478643, 0.9773724471196608, 0.019547448942393218, 0.004004400942378385, 0.9930914337098395, 0.0032035207539027086, 0.9705577925807072, 0.0271756181922598, 0.46389844796030416, 0.3347720758476422, 0.2008632455085853, 0.04462010432578916, 0.14377589171643174, 0.8105985619185031, 0.7618137944136688, 0.16015403632560082, 0.07791277442867067, 0.7078396544821959, 0.1538781857569991, 0.14020012480082142, 0.6959923506071761, 0.15933890810603848, 0.14531708419270709, 0.35584866663162834, 0.3265278027144155, 0.3171984369225751, 0.8233726634003137, 0.050729121441725485, 0.12487168354886274, 0.3719542821491652, 0.5121993393529488, 0.1158546124726908, 0.44987368708335956, 0.45325619600879835, 0.09471024991228623, 0.7895612404012451, 0.13757506461536845, 0.07177829458193137, 0.5629519256928434, 0.1862397348156775, 0.2518469141257457, 0.0035811925127488846, 0.0035811925127488846, 0.991990326031441, 0.8086487456747071, 0.06469189965397658, 0.12938379930795316, 0.3715352046218049, 0.4688420439275157, 0.15922937340934495, 0.0028222448957739375, 0.3189136732224549, 0.6787498974336319, 0.15544848146566673, 0.36271312341988904, 0.4798627036548842], \"Term\": [\"available\", \"available\", \"available\", \"baseball\", \"baseball\", \"baseball\", \"believe\", \"believe\", \"believe\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"bible\", \"big\", \"big\", \"big\", \"book\", \"book\", \"book\", \"christ\", \"christian\", \"christian\", \"come\", \"come\", \"come\", \"data\", \"data\", \"data\", \"did\", \"did\", \"did\", \"didn\", \"didn\", \"didn\", \"does\", \"does\", \"does\", \"doesn\", \"doesn\", \"doesn\", \"earth\", \"earth\", \"earth\", \"edu\", \"edu\", \"edu\", \"fact\", \"fact\", \"fact\", \"far\", \"far\", \"far\", \"field\", \"field\", \"field\", \"game\", \"game\", \"game\", \"games\", \"games\", \"games\", \"god\", \"god\", \"god\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"high\", \"high\", \"high\", \"hit\", \"hit\", \"hit\", \"information\", \"information\", \"information\", \"jehovah\", \"jesus\", \"just\", \"just\", \"just\", \"know\", \"know\", \"know\", \"launch\", \"launch\", \"launch\", \"league\", \"league\", \"life\", \"life\", \"life\", \"little\", \"little\", \"little\", \"long\", \"long\", \"long\", \"lord\", \"lord\", \"lot\", \"lot\", \"lot\", \"lunar\", \"lunar\", \"lunar\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"maybe\", \"maybe\", \"maybe\", \"mission\", \"mission\", \"mission\", \"moon\", \"moon\", \"moon\", \"nasa\", \"nasa\", \"nasa\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"orbit\", \"orbit\", \"orbit\", \"order\", \"order\", \"order\", \"people\", \"people\", \"people\", \"players\", \"players\", \"players\", \"point\", \"point\", \"point\", \"power\", \"power\", \"power\", \"probably\", \"probably\", \"probably\", \"program\", \"program\", \"program\", \"question\", \"question\", \"question\", \"read\", \"read\", \"read\", \"real\", \"real\", \"real\", \"really\", \"really\", \"really\", \"right\", \"right\", \"right\", \"run\", \"run\", \"run\", \"runs\", \"runs\", \"runs\", \"said\", \"said\", \"said\", \"satellite\", \"satellite\", \"say\", \"say\", \"say\", \"science\", \"science\", \"science\", \"second\", \"second\", \"second\", \"shuttle\", \"shuttle\", \"solar\", \"solar\", \"solar\", \"space\", \"space\", \"space\", \"spacecraft\", \"spacecraft\", \"sure\", \"sure\", \"sure\", \"team\", \"team\", \"team\", \"thing\", \"thing\", \"thing\", \"things\", \"things\", \"things\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"true\", \"true\", \"true\", \"use\", \"use\", \"use\", \"used\", \"used\", \"used\", \"want\", \"want\", \"want\", \"way\", \"way\", \"way\", \"won\", \"won\", \"won\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"year\", \"year\", \"year\", \"years\", \"years\", \"years\"]}, \"mdsDat\": {\"y\": [-0.02370551917416827, -0.1315997052526537, 0.15530522442682193], \"cluster\": [1, 1, 1], \"Freq\": [44.83172540632584, 30.678790091602092, 24.489484502072077], \"topics\": [1, 2, 3], \"x\": [-0.1892307102255956, 0.11806813562761406, 0.07116257459798164]}, \"R\": 30, \"lambda.step\": 0.01, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Term\": [\"space\", \"game\", \"nasa\", \"year\", \"god\", \"games\", \"launch\", \"baseball\", \"won\", \"team\", \"data\", \"jesus\", \"shuttle\", \"orbit\", \"players\", \"league\", \"solar\", \"spacecraft\", \"edu\", \"mission\", \"people\", \"satellite\", \"program\", \"bible\", \"runs\", \"run\", \"science\", \"hit\", \"new\", \"field\", \"jesus\", \"bible\", \"god\", \"jehovah\", \"christ\", \"christian\", \"lord\", \"read\", \"said\", \"people\", \"man\", \"believe\", \"question\", \"does\", \"life\", \"true\", \"maybe\", \"know\", \"say\", \"word\", \"fact\", \"want\", \"just\", \"thing\", \"didn\", \"point\", \"did\", \"doesn\", \"come\", \"right\", \"think\", \"good\", \"really\", \"make\", \"things\", \"way\", \"time\", \"launch\", \"space\", \"nasa\", \"data\", \"orbit\", \"shuttle\", \"solar\", \"satellite\", \"spacecraft\", \"mission\", \"program\", \"science\", \"available\", \"earth\", \"information\", \"power\", \"lunar\", \"moon\", \"high\", \"long\", \"use\", \"big\", \"work\", \"used\", \"real\", \"need\", \"hit\", \"years\", \"sure\", \"second\", \"time\", \"year\", \"new\", \"good\", \"just\", \"think\", \"won\", \"games\", \"baseball\", \"league\", \"game\", \"players\", \"run\", \"team\", \"field\", \"runs\", \"edu\", \"book\", \"best\", \"year\", \"hit\", \"order\", \"new\", \"years\", \"better\", \"moon\", \"far\", \"little\", \"lunar\", \"second\", \"probably\", \"great\", \"time\", \"high\", \"information\", \"lot\", \"way\", \"think\", \"did\"], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8004, 0.7994, 0.7993, 0.799, 0.7987, 0.7974, 0.7925, 0.728, 0.6958, 0.6738, 0.6545, 0.6539, 0.6341, 0.6324, 0.6293, 0.609, 0.6081, 0.6011, 0.599, 0.5889, 0.5664, 0.5646, 0.5457, 0.5306, 0.5165, 0.5066, 0.4946, 0.4859, 0.4797, 0.4712, 0.4399, 0.3609, 0.4433, 0.3758, 0.4574, 0.2286, -0.2305, 1.1746, 1.1744, 1.1738, 1.1668, 1.1617, 1.1592, 1.1568, 1.1526, 1.152, 1.1463, 1.1279, 1.1005, 1.0658, 0.796, 0.7484, 0.7424, 0.6364, 0.5766, 0.5376, 0.5128, 0.5113, 0.4522, 0.4266, 0.3921, 0.2959, 0.27, 0.1995, 0.169, 0.0812, 0.0804, 0.0614, 0.0386, 0.0501, -0.2704, -0.4643, -0.6559, 1.4, 1.3992, 1.3962, 1.3883, 1.372, 1.3599, 1.2371, 1.1982, 1.1884, 1.1878, 1.1494, 1.0745, 1.0315, 1.0197, 0.9299, 0.8844, 0.7617, 0.6738, 0.6435, 0.6092, 0.6028, 0.5393, 0.5213, 0.4614, 0.4423, 0.3145, 0.2605, 0.2597, 0.2497, 0.2342, 0.0239, -0.5259, -0.3458], \"Freq\": [1248.0, 478.0, 482.0, 708.0, 652.0, 302.0, 346.0, 288.0, 279.0, 403.0, 299.0, 409.0, 283.0, 281.0, 234.0, 203.0, 255.0, 257.0, 333.0, 251.0, 733.0, 220.0, 231.0, 273.0, 224.0, 216.0, 223.0, 279.0, 478.0, 215.0, 408.65754917081335, 272.6031667852126, 650.3316868824447, 217.1800955008034, 203.24475561963123, 205.1316501726713, 196.8266538370376, 227.0858287704005, 317.9185881031314, 645.4456415551235, 172.26999693243872, 302.1786110619039, 152.95271974528225, 429.6722444013333, 245.91797361790984, 211.22885958878908, 170.5910290599572, 545.9515157087928, 395.5007988434958, 149.84831622427413, 180.3375949859097, 263.62920461788997, 631.8741458378096, 176.07454523193957, 184.73729810587312, 238.2487558900385, 350.1483592185043, 199.25384736445162, 158.74352383713165, 262.51100576897716, 546.0529885897399, 422.28499209614296, 234.2961336119037, 265.99243909825464, 207.14898594969645, 266.22909961379565, 267.12381354101194, 344.03680073524106, 1239.6652947694306, 478.5601542829965, 295.0384802268839, 276.0901644219048, 277.3345394953074, 249.5114897041932, 214.34562290262852, 250.06135531404868, 242.61076327204745, 219.03241886413744, 205.71228359248857, 185.31564310339084, 340.5206469160817, 146.0355117500524, 144.2251340924013, 113.93697331920595, 150.18500116868157, 135.1822256169666, 166.0993242149111, 167.78076222252648, 95.15221766720329, 106.26961917849833, 134.24267751314568, 73.30481641587312, 87.50954772409293, 104.73273117262862, 161.2472551532161, 69.57145660803364, 76.79842935826827, 244.7769130362458, 225.966964988604, 154.36593547854287, 153.70315220536958, 157.49287472324346, 124.89703939842812, 277.32230448468255, 300.1572681403641, 285.04954893984234, 199.56526280768912, 461.6369790724546, 223.5429566850265, 182.60968836845728, 327.4020044440073, 173.54702571780712, 180.49526598292576, 257.76710159677646, 140.8381828147897, 139.21476142019503, 481.11129083298994, 173.5568806442626, 126.92500387369407, 251.05229299870865, 213.2405424070519, 192.95057012740736, 123.85906951658173, 111.73737526418125, 95.42070534588116, 81.05872082285812, 89.73683704107, 98.00957185154243, 78.23391383094773, 238.4182293074253, 81.72799292666592, 70.8029065961886, 75.96226928949594, 118.51530688713348, 113.54135259047712, 82.54031023882807], \"Total\": [1248.0, 478.0, 482.0, 708.0, 652.0, 302.0, 346.0, 288.0, 279.0, 403.0, 299.0, 409.0, 283.0, 281.0, 234.0, 203.0, 255.0, 257.0, 333.0, 251.0, 733.0, 220.0, 231.0, 273.0, 224.0, 216.0, 223.0, 279.0, 478.0, 215.0, 409.39554123467093, 273.38840522346374, 652.2612265597122, 217.88574937709248, 203.9763176789583, 206.1257611549371, 198.75639998920647, 244.5840837702197, 353.6202453474714, 733.8830271810821, 199.700921030724, 350.5215202507077, 180.96025059654352, 509.2265884781248, 292.3516603025372, 256.26306213352433, 207.14442845860407, 667.5931089453364, 484.62680780988273, 185.49463014976354, 228.31364863230723, 334.36291764504364, 816.6913063041818, 231.02758349953308, 245.8534574039253, 320.2077845921358, 476.30041471192794, 273.402578927359, 219.17079824738084, 365.5248912542505, 784.4913805786451, 656.551769081504, 335.48678239405365, 407.46828650762313, 292.43911200683743, 472.5092638640948, 750.318955884683, 346.45228651670675, 1248.6262169917195, 482.3006971922669, 299.4285773055296, 281.63626031374383, 283.6254140243966, 255.7878531738395, 220.64805081352256, 257.5838367494341, 251.3396036551435, 231.12323477458492, 223.0853431786559, 208.06454794975818, 500.751785510005, 225.2222137728612, 223.76851454218962, 196.5321747791951, 275.0238259418465, 257.40049860867686, 324.2037054724044, 327.9972992785017, 197.3234047585727, 226.08893842376452, 295.6385399249983, 177.74207254232581, 217.7418722173724, 279.64051019064584, 443.87696392672547, 209.09748766458537, 230.98659589005774, 750.318955884683, 708.6557240283519, 478.6004373895752, 656.551769081504, 816.6913063041818, 784.4913805786451, 279.2365940786609, 302.49475100639273, 288.11194895487665, 203.3126243802162, 478.0337806241233, 234.29498513480837, 216.40973976444513, 403.4056009500746, 215.92618606223581, 224.70352797343972, 333.4949245324984, 196.38309948026878, 202.64861743497613, 708.6557240283519, 279.64051019064584, 214.03289684731507, 478.6004373895752, 443.87696392672547, 414.01224675466983, 275.0238259418465, 249.7002215758374, 227.2226523999322, 196.5321747791951, 230.98659589005774, 257.1480008803926, 233.24744769971468, 750.318955884683, 257.40049860867686, 225.2222137728612, 245.41844263652197, 472.5092638640948, 784.4913805786451, 476.30041471192794], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.5751, -3.9799, -3.1105, -4.2072, -4.2735, -4.2643, -4.3056, -4.1626, -3.8261, -3.118, -4.4389, -3.8769, -4.5578, -3.5249, -4.0829, -4.235, -4.4487, -3.2854, -3.6078, -4.5783, -4.3931, -4.0134, -3.1393, -4.417, -4.369, -4.1146, -3.7296, -4.2934, -4.5207, -4.0176, -3.2852, -3.5423, -4.1314, -4.0045, -4.2545, -4.0036, -4.0002, -3.3678, -2.086, -3.0378, -3.5215, -3.5879, -3.5834, -3.6891, -3.841, -3.6869, -3.7171, -3.8194, -3.8821, -3.9865, -3.3781, -4.2247, -4.2372, -4.473, -4.1967, -4.302, -4.096, -4.0859, -4.6531, -4.5426, -4.3089, -4.914, -4.7368, -4.5572, -4.1257, -4.9662, -4.8674, -3.7082, -3.7882, -4.1693, -4.1736, -4.1492, -4.3811, -3.3581, -3.279, -3.3306, -3.6871, -2.8485, -3.5737, -3.7759, -3.1921, -3.8268, -3.7876, -3.4312, -4.0357, -4.0473, -2.8072, -3.8268, -4.1397, -3.4576, -3.6208, -3.7208, -4.1641, -4.2671, -4.425, -4.5881, -4.4864, -4.3982, -4.6236, -3.5092, -4.5799, -4.7234, -4.653, -4.2082, -4.2511, -4.57]}};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2645446321562401988629944\", ldavis_el2645446321562401988629944_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2645446321562401988629944\", ldavis_el2645446321562401988629944_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2645446321562401988629944\", ldavis_el2645446321562401988629944_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "2      44.831725        1       1 -0.189231 -0.023706\n",
       "0      30.678790        1       2  0.118068 -0.131600\n",
       "1      24.489485        1       3  0.071163  0.155305, topic_info=     Category         Freq         Term        Total  loglift  logprob\n",
       "term                                                                  \n",
       "81    Default  1248.000000        space  1248.000000  30.0000  30.0000\n",
       "26    Default   478.000000         game   478.000000  29.0000  29.0000\n",
       "55    Default   482.000000         nasa   482.000000  28.0000  28.0000\n",
       "98    Default   708.000000         year   708.000000  27.0000  27.0000\n",
       "28    Default   652.000000          god   652.000000  26.0000  26.0000\n",
       "27    Default   302.000000        games   302.000000  25.0000  25.0000\n",
       "40    Default   346.000000       launch   346.000000  24.0000  24.0000\n",
       "2     Default   288.000000     baseball   288.000000  23.0000  23.0000\n",
       "94    Default   279.000000          won   279.000000  22.0000  22.0000\n",
       "84    Default   403.000000         team   403.000000  21.0000  21.0000\n",
       "14    Default   299.000000         data   299.000000  20.0000  20.0000\n",
       "37    Default   409.000000        jesus   409.000000  19.0000  19.0000\n",
       "79    Default   283.000000      shuttle   283.000000  18.0000  18.0000\n",
       "58    Default   281.000000        orbit   281.000000  17.0000  17.0000\n",
       "62    Default   234.000000      players   234.000000  16.0000  16.0000\n",
       "41    Default   203.000000       league   203.000000  15.0000  15.0000\n",
       "80    Default   255.000000        solar   255.000000  14.0000  14.0000\n",
       "82    Default   257.000000   spacecraft   257.000000  13.0000  13.0000\n",
       "22    Default   333.000000          edu   333.000000  12.0000  12.0000\n",
       "53    Default   251.000000      mission   251.000000  11.0000  11.0000\n",
       "60    Default   733.000000       people   733.000000  10.0000  10.0000\n",
       "75    Default   220.000000    satellite   220.000000   9.0000   9.0000\n",
       "66    Default   231.000000      program   231.000000   8.0000   8.0000\n",
       "6     Default   273.000000        bible   273.000000   7.0000   7.0000\n",
       "73    Default   224.000000         runs   224.000000   6.0000   6.0000\n",
       "72    Default   216.000000          run   216.000000   5.0000   5.0000\n",
       "77    Default   223.000000      science   223.000000   4.0000   4.0000\n",
       "34    Default   279.000000          hit   279.000000   3.0000   3.0000\n",
       "57    Default   478.000000          new   478.000000   2.0000   2.0000\n",
       "25    Default   215.000000        field   215.000000   1.0000   1.0000\n",
       "...       ...          ...          ...          ...      ...      ...\n",
       "41     Topic3   199.565263       league   203.312624   1.3883  -3.6871\n",
       "26     Topic3   461.636979         game   478.033781   1.3720  -2.8485\n",
       "62     Topic3   223.542957      players   234.294985   1.3599  -3.5737\n",
       "72     Topic3   182.609688          run   216.409740   1.2371  -3.7759\n",
       "84     Topic3   327.402004         team   403.405601   1.1982  -3.1921\n",
       "25     Topic3   173.547026        field   215.926186   1.1884  -3.8268\n",
       "73     Topic3   180.495266         runs   224.703528   1.1878  -3.7876\n",
       "22     Topic3   257.767102          edu   333.494925   1.1494  -3.4312\n",
       "8      Topic3   140.838183         book   196.383099   1.0745  -4.0357\n",
       "4      Topic3   139.214761         best   202.648617   1.0315  -4.0473\n",
       "98     Topic3   481.111291         year   708.655724   1.0197  -2.8072\n",
       "34     Topic3   173.556881          hit   279.640510   0.9299  -3.8268\n",
       "59     Topic3   126.925004        order   214.032897   0.8844  -4.1397\n",
       "57     Topic3   251.052293          new   478.600437   0.7617  -3.4576\n",
       "99     Topic3   213.240542        years   443.876964   0.6738  -3.6208\n",
       "5      Topic3   192.950570       better   414.012247   0.6435  -3.7208\n",
       "54     Topic3   123.859070         moon   275.023826   0.6092  -4.1641\n",
       "24     Topic3   111.737375          far   249.700222   0.6028  -4.2671\n",
       "44     Topic3    95.420705       little   227.222652   0.5393  -4.4250\n",
       "49     Topic3    81.058721        lunar   196.532175   0.5213  -4.5881\n",
       "78     Topic3    89.736837       second   230.986596   0.4614  -4.4864\n",
       "65     Topic3    98.009572     probably   257.148001   0.4423  -4.3982\n",
       "32     Topic3    78.233914        great   233.247448   0.3145  -4.6236\n",
       "88     Topic3   238.418229         time   750.318956   0.2605  -3.5092\n",
       "33     Topic3    81.727993         high   257.400499   0.2597  -4.5799\n",
       "35     Topic3    70.802907  information   225.222214   0.2497  -4.7234\n",
       "48     Topic3    75.962269          lot   245.418443   0.2342  -4.6530\n",
       "93     Topic3   118.515307          way   472.509264   0.0239  -4.2082\n",
       "87     Topic3   113.541353        think   784.491381  -0.5259  -4.2511\n",
       "16     Topic3    82.540310          did   476.300415  -0.3458  -4.5700\n",
       "\n",
       "[136 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "1         1  0.033643  available\n",
       "1         2  0.889147  available\n",
       "1         3  0.072093  available\n",
       "2         1  0.003471   baseball\n",
       "2         2  0.010413   baseball\n",
       "2         3  0.989199   baseball\n",
       "3         1  0.861573    believe\n",
       "3         2  0.051352    believe\n",
       "3         3  0.088440    believe\n",
       "4         1  0.172713       best\n",
       "4         2  0.138170       best\n",
       "4         3  0.685916       best\n",
       "5         1  0.350231     better\n",
       "5         2  0.183569     better\n",
       "5         3  0.466170     better\n",
       "6         1  0.998579      bible\n",
       "7         1  0.359815        big\n",
       "7         2  0.481443        big\n",
       "7         3  0.157102        big\n",
       "8         1  0.229144       book\n",
       "8         2  0.056013       book\n",
       "8         3  0.717984       book\n",
       "10        1  0.995214     christ\n",
       "11        1  0.994538  christian\n",
       "11        3  0.004851  christian\n",
       "12        1  0.725462       come\n",
       "12        2  0.100378       come\n",
       "12        3  0.173381       come\n",
       "14        1  0.003340       data\n",
       "14        2  0.985210       data\n",
       "...     ...       ...        ...\n",
       "89        1  0.823373       true\n",
       "89        2  0.050729       true\n",
       "89        3  0.124872       true\n",
       "90        1  0.371954        use\n",
       "90        2  0.512199        use\n",
       "90        3  0.115855        use\n",
       "91        1  0.449874       used\n",
       "91        2  0.453256       used\n",
       "91        3  0.094710       used\n",
       "92        1  0.789561       want\n",
       "92        2  0.137575       want\n",
       "92        3  0.071778       want\n",
       "93        1  0.562952        way\n",
       "93        2  0.186240        way\n",
       "93        3  0.251847        way\n",
       "94        1  0.003581        won\n",
       "94        2  0.003581        won\n",
       "94        3  0.991990        won\n",
       "95        1  0.808649       word\n",
       "95        2  0.064692       word\n",
       "95        3  0.129384       word\n",
       "96        1  0.371535       work\n",
       "96        2  0.468842       work\n",
       "96        3  0.159229       work\n",
       "98        1  0.002822       year\n",
       "98        2  0.318914       year\n",
       "98        3  0.678750       year\n",
       "99        1  0.155448      years\n",
       "99        2  0.362713      years\n",
       "99        3  0.479863      years\n",
       "\n",
       "[253 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "g_vectorizer = CountVectorizer(max_df=0.95, min_df=2, analyzer='word',\n",
    "    max_features=100, stop_words=stop_words, token_pattern = r'\\b[a-zA-Z]{3,}\\b')\n",
    "\n",
    "fs = g_vectorizer.fit_transform(ds1.data)\n",
    "lda = LDA.fit(fs)\n",
    "    \n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, fs, g_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
